{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalizacion de texto.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBShw2cu8NG7tV83ffwl2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaier9/Procesamiento-del-lenguaje-natural/blob/master/Normalizacion_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex2574cQGh6R"
      },
      "source": [
        "# **Normalizacion de Texto** (como aplicación de las expresiones regulares)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wzomdwEGc2I",
        "outputId": "09a6fae1-eadb-4051-d31e-9672dc59dd45"
      },
      "source": [
        "import nltk\n",
        "# En Python \\n es un salto de linea\n",
        "print('esta es \\n una prueba')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "esta es \n",
            " una prueba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AigIe0xxHgEt",
        "outputId": "6dde1c5b-ffb9-4b9e-b4e9-74e5dcf215f9"
      },
      "source": [
        "# raw; al interponer la r delante del string, lo interpreta como texto plano\n",
        "print(r'esta es \\n una prueba')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "esta es \\n una prueba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE_vV4klRc-_"
      },
      "source": [
        "**Tokenización:** Es el proceso mediante el cual se sub-divide una cadena de texto en unidades linguísticas mínimas(palabras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vHNJJqR0rm"
      },
      "source": [
        "texto = \"\"\" Cuando sea el rey del mundo (imaginaba él en su cabeza) no tendré que  preocuparme por estas bobadas. \n",
        "            Era solo un niño de 7 años, pero pensaba que podría ser cualquier cosa que su imaginación le permitiera \n",
        "            visualizar en su cabeza ...\"\"\" "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0uPT1-9VS7b",
        "outputId": "112aa084-9422-4cb7-e69e-81b9b9ac2837"
      },
      "source": [
        "# Caso 1: Tokenizar por espacios vacios\n",
        "import re\n",
        "print(re.split(r' ', texto))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', '(imaginaba', 'él', 'en', 'su', 'cabeza)', 'no', 'tendré', 'que', '', 'preocuparme', 'por', 'estas', 'bobadas.', '\\n', '', '', '', '', '', '', '', '', '', '', '', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años,', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', '\\n', '', '', '', '', '', '', '', '', '', '', '', 'visualizar', 'en', 'su', 'cabeza', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te-Dg0GLVr_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee12b7f5-d30b-45ce-fe31-7a35cb5dfc6b"
      },
      "source": [
        "# Caso 2: Tokenizacion unsando expresiones regulares\n",
        "print(re.split(r'[ \\t\\n]+', texto))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', '(imaginaba', 'él', 'en', 'su', 'cabeza)', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas.', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años,', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kEufADzJIwX",
        "outputId": "6e9bc3e7-c059-4dbb-9d20-decf10786241"
      },
      "source": [
        "# Caso 3\n",
        "print(re.split(r'[ \\W\\t\\n]+', texto))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'Cuando', 'sea', 'el', 'rey', 'del', 'mundo', 'imaginaba', 'él', 'en', 'su', 'cabeza', 'no', 'tendré', 'que', 'preocuparme', 'por', 'estas', 'bobadas', 'Era', 'solo', 'un', 'niño', 'de', '7', 'años', 'pero', 'pensaba', 'que', 'podría', 'ser', 'cualquier', 'cosa', 'que', 'su', 'imaginación', 'le', 'permitiera', 'visualizar', 'en', 'su', 'cabeza', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gubpLc9wKO_y"
      },
      "source": [
        "#**Tokenizador de NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUg2JRoWKLBQ",
        "outputId": "db5a5884-f835-45de-adf0-0aa2d98316a0"
      },
      "source": [
        "texto = 'En los E.U. esa postal vale $15.50 ...'\n",
        "print(re.split(r'[ \\W\\t\\n]+', texto))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['En', 'los', 'E', 'U', 'esa', 'postal', 'vale', '15', '50', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goul4XtZK0ot",
        "outputId": "d8d37c4e-d48f-440b-d397-05576b5cefb7"
      },
      "source": [
        "pattern = r'''(?x)                  # Flag para iniciar el modo verbose\n",
        "              (?:[A-Z]\\.)+          # Hace match con abreviaciones como U.S.A.\n",
        "              | \\w+(?:-\\w+)*        # Hace match con palabras que pueden tener un guión interno\n",
        "              | \\$?\\d+(?:\\.\\d+)?%?  # Hace match con dinero o porcentajes como $15.5 o 100%\n",
        "              | \\.\\.\\.              # Hace match con puntos suspensivos\n",
        "              | [][.,;\"'?():-_`]    # Hace match con signos de puntuación\n",
        "'''\n",
        "nltk.regexp_tokenize(texto, pattern)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['En', 'los', 'E.U.', 'esa', 'postal', 'vale', '$15.50', '...']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}